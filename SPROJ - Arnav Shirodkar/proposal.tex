\documentclass[../main.tex]{subfiles}
\graphicspath{{\subfix{../imgs/}}}
\begin{document}
\newpage
\section{Final Remarks}

\subsection{Proposal}
The conception of this SPROJ can be split into two constituent parts. First, I would like to create a generalized system that is able learn and encode complex concepts from auditory or symbolic (MIDI) data in realtime. This system will directly reference and build Pesek's research on the Compositional Hierarchical Model, and will serve as a sort of ``Memory Unit" for our responsive unit. Secondly, there must be a responsive system built on top of our ``Memory Unit" that is able to retrieve output from the model and generate some kind of perceptual output. For the purposes of the project, this will music, but in reality it should be generalizable beyond music (eg. Music Visualization.) The key steps involved are described in greater detail below.

\begin{enumerate}
    \item The System should be able to parse auditory streams in real time, either as input in a symbolic form (Eg. MIDI), or to extract information from the spectral or even cepstral domain. This auditory data will be present to the machine learning model as input events, similar to what is described in M. Pesek's model. The ability to parse auditory information is not the main focus of the project, and thus this will be built as a separate module that makes use of open-source code and tools as much as possible. Furthermore, given that the system is intended to work in real-time, it is necessary to minimize computationally heavy operations as much as possible.  To minimize the overall amount of computation involved in the model's learning, I believe all incoming auditory information should be sampled and converted to MIDI streams (as done in Voyager).
    
    \item Rather than learn on a set of training data, the model will ideally encode learned concepts from the input-stream in real-time. This is where the model will differ significantly from Pesek's model. As a comparison, Pesek's model learns encoded concepts and builds from the bottom up, examining an entire piece of music. This is akin to an expert analyzing a piece of music with the entire score laid out in front of them. By contrast, my intended model will listen to music more like humans do, and learn encoded concepts from left to right, incrementally adding to all layers simultaneously. This is closer to an improvisor in real-time, making subconscious musical decisions based on what they have heard \textit{so far} and what they \textit{choose to remember}.This necessitates significant changes in the algorithms proposed by Pesek, and possibly in the output generated by the system.

    \item To adequately evaluate the concepts learned by the system, a ``snapshot" feature that captures incrementally learned concepts in the model will be necessary. In this manner, we can present the model with different kinds of pre-recorded musical input and examine how it composes parts together into higher level concepts \textit{over time}.

    \item Like in Voyager, the system must periodically call a subroutine that returns output based on both the learned concepts as well as the input signal. This results from the subroutine are handed to our "performing" unit, which is built as a separate module. 

    \item For the sake of simplicity and ease of prototyping, our "performing unit" can be built with Max/MSP, a visual programming language for music and multimedia. Within Max, a variety of algorithms can be employed to construct a musical output based on the data returned by the model. (Max is also capable of rendering generated visuals)
\end{enumerate}

\subsection {Conclusion}
In conclusion, the proposed SPROJ project will involved the construction of multi-part system that emulates human auditory perception, learns encoded concepts, and is then able to respond to these concepts in a manner that can be perceived by humans. Given the huge scope of the project, a majority of time and effort will be devoted to model's ability to learn encoded concepts that can be sufficiently interpreted, unlike deep neural architectures that are characteristically, black box architectures. The accuracy of translation from auditory data to symbolic data, as well as the efficacy of the ``performing unit" will be secondary to the overall research goal and will be covered in brief.

\end{document}