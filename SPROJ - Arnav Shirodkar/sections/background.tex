\documentclass[../main.tex]{subfiles}
\graphicspath{{\subfix{../imgs/}}}
\begin{document}
\newpage

\chapter{Background}

\section{A Brief History of Generative AI}
Generative AI refers to a subset of artificial intelligence techniques that focus on generating new content, be it text, images, music, or other forms of data. This technology has evolved significantly, from rule-based systems to advanced neural networks.

\subsection{Early Systems}
Initial generative models were simplistic, using rule-based systems for tasks like automatic report generation. However, they lacked the ability to create complex, human-like content. For references, look into early works on generative systems in AI, such as Buchanan et al.’s “A Model of Rule-Based Understanding in Reading” (1979).
Rise of Neural Networks:

\subsection{Deep Architectures}


\subsection{Generative AI in Image Processing}
- Discuss models like stable diffusion, deepfake technology etc. leading to the creation of Dall-E and more

\subsection{Generative AI in Sequence Modeling Tasks}

\textbf{Recurrent Neural Networks} — The advent of neural networks brought a paradigm shift. Recurrent Neural Networks (RNNs) and later, Long Short-Term Memory networks (LSTMs), allowed for better handling of sequential data, crucial for tasks like language modeling.

\textbf{Long Short-Term Memory Networks} — Hochreiter & Schmidhuber’s “Long Short-Term Memory” (1997) is a seminal paper in this area.
Transformers and Beyond:

\textbf{Transformers} — The introduction of transformer models, as seen in Vaswani et al.’s “Attention Is All You Need” (2017), marked a turning point. These models outperformed previous architectures in various tasks, leading to their widespread adoption. Vaswani et al.’s paper is a must-read for understanding the foundation of modern transformer models.

\subsection{Impact of Generative AI in Various Fields}

Generative AI has found applications in diverse fields, from creating realistic images and art to generating human-like text and aiding in scientific discovery.
For examples of AI in art and text generation, see “A Neural Algorithm of Artistic Style” by Gatys et al. (2015) and Radford et al.’s “Language Models are Unsupervised Multitask Learners” (2019), respectively.
Versatility of Generative Models:

These models are not just limited to creative tasks but also assist in data augmentation, simulation for autonomous vehicles, and more.
Look into “Playing for Data: Ground Truth from Computer Games” by Richter et al. (2016) for insights into data augmentation for autonomous driving.

\section {Music Information Retrieval}


\end{document}